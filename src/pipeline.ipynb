{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from q_value_calc_crosslinks import calcQ\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import get_target_id\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "dataset = {1: { 'type': 'crosslink_data',\n",
    "                'name':'AChernev_080219_HeLa_RNA_UV',\n",
    "                'comparison':'opti_'},\n",
    "           2: { 'type': 'crosslink_data',\n",
    "                'name':'M_Raabe_A_Wulf_220421_270421_Expl3_Ecoli_XL_UV_S30_LB_bRPfrac_11',\n",
    "                'comparison':'perc'},\n",
    "           3: { 'type': 'crosslink_data',\n",
    "                'name':'M_Raabe_A_Wulf_220421_290421_Expl3_Ecoli_XL_DEB_S30_LB_bRPfrac_12',\n",
    "                'comparison':'perc'},\n",
    "           4: { 'type': 'crosslink_data',\n",
    "                'name':'MRaabe_LW_091221_171221_Expl2_XL_Ecoli_NM_S30_bRP_rep1_11',\n",
    "                'comparison':'perc'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = f\"../data/{dataset[i]['type']}/{dataset[i]['name']}.pkl\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read original dataframes\n",
    "original_df = pd.read_pickle(input_file)\n",
    "\n",
    "# filter dataframes\n",
    "filter_col = 'PSMId'\n",
    "filter_val = 1\n",
    "original_df_filtered = original_df.loc[original_df[filter_col] == filter_val,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Score','peplen', 'NuXL:isXL', 'NuXL:modds', 'NuXL:pl_modds', \n",
    "                'NuXL:mass_error_p', 'NuXL:tag_XLed', 'NuXL:tag_unshifted' ,\n",
    "                'NuXL:tag_shifted', 'missed_cleavages', 'NuXL:ladder_score',\n",
    "                'variable_modifications']\n",
    "\n",
    "# filter data and sort according to descending score\n",
    "original_df = original_df.filter(np.concatenate([features,['ScanNr', 'rank', 'Label', 'PSMId']]))\n",
    "original_df.sort_values('Score',ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncating to 500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# determine minority class \n",
    "minority_class = min({len(original_df.loc[original_df['NuXL:isXL'] == 0]), len(original_df.loc[original_df['NuXL:isXL'] == 1])})\n",
    "class_threshold = 500\n",
    "if (minority_class > class_threshold):\n",
    "    print(\"Truncating to \" + str(class_threshold) + \"\\n\") \n",
    "    minority_class = class_threshold\n",
    "\n",
    "# define training data (peptides with top and bottom scores of each class with PSMId = 1)\n",
    "pep_top = original_df.loc[(original_df['NuXL:isXL'] == 0) & (original_df[filter_col] == filter_val)][:int(minority_class/2)]\n",
    "pep_bottom = original_df.loc[(original_df['NuXL:isXL'] == 0) & (original_df[filter_col] == filter_val)][-int(minority_class/2):]\n",
    "XL_top = original_df.loc[(original_df['NuXL:isXL'] == 1) & (original_df[filter_col] == filter_val)][:int(minority_class/2)]\n",
    "XL_bottom = original_df.loc[(original_df['NuXL:isXL'] == 1) & (original_df[filter_col] == filter_val)][-int(minority_class/2):]\n",
    "train_idx = np.concatenate([pep_top.index, pep_bottom.index, XL_top.index, XL_bottom.index])\n",
    "\n",
    "# set train labels for training\n",
    "original_df.loc[pep_top.index,'train_label'] = 1\n",
    "original_df.loc[pep_bottom.index,'train_label'] = 0\n",
    "original_df.loc[XL_top.index,'train_label'] = 1\n",
    "original_df.loc[XL_bottom.index,'train_label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mail\\AppData\\Local\\Temp\\ipykernel_26080\\2997351114.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(\n",
      "c:\\Users\\mail\\Research-Project\\src\\q_value_calc_crosslinks.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(scoreColName, ascending=ascending, inplace=True)\n",
      "c:\\Users\\mail\\Research-Project\\src\\q_value_calc_crosslinks.py:100: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[labelColName].replace(to_replace=-1, value=0, inplace=True)\n",
      "c:\\Users\\mail\\Research-Project\\src\\q_value_calc_crosslinks.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[labelColName].replace(to_replace=-1, value=0, inplace=True)\n",
      "c:\\Users\\mail\\Research-Project\\src\\q_value_calc_crosslinks.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['FDR'] = (range(1, len(df) + 1) / df[labelColName].cumsum()) - 1\n",
      "c:\\Users\\mail\\Research-Project\\src\\q_value_calc_crosslinks.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['q-val'] = df['FDR'][::-1].cummin()[::-1]\n"
     ]
    }
   ],
   "source": [
    "# define function for setting new rank column\n",
    "def set_new_rank(x):\n",
    "    x.sort_values(\"Score\",ascending=False,inplace=True)\n",
    "    x[\"new_PSMId\"] = range(1,len(x) + 1)\n",
    "    return x\n",
    "\n",
    "# initialise the k-fold cross validator\n",
    "no_split = 5\n",
    "kf = KFold(n_splits=no_split, shuffle=True, random_state=1)\n",
    "\n",
    "param_grid = {\n",
    "        'C': np.power(float(2), [-5,-1,1,5,7,11,15])\n",
    "    }\n",
    "# create the pipeline\n",
    "pipe = make_pipeline(MinMaxScaler(), \n",
    "                        GridSearchCV(\n",
    "                            estimator=SVC(kernel='linear', probability=True), \n",
    "                            param_grid=param_grid, \n",
    "                            n_jobs=-1,\n",
    "                            scoring=\"accuracy\",\n",
    "                            cv=kf, \n",
    "                            refit=True))\n",
    "pipe.fit(original_df.loc[train_idx, features], original_df.loc[train_idx, 'train_label'])\n",
    "original_df['Score_old'] = original_df['Score']\n",
    "original_df.sort_values(['Score'], ascending=[False], inplace=True)\n",
    "original_df['Score'] = 1.0 - pipe.predict_proba(original_df.loc[:,features])\n",
    "# rerank PSMs\n",
    "original_df = original_df.groupby(\"ScanNr\")\\\n",
    "    .apply(\n",
    "        lambda x: set_new_rank(x)\n",
    "    )\n",
    "original_df.index = original_df.index.droplevel('ScanNr')\n",
    "\n",
    "output_file = re.sub('.pkl', '_SVM.pkl', input_file)\n",
    "original_df.to_pickle(output_file)\n",
    "# filter for rank = 0\n",
    "original_df_filtered_new = original_df.loc[original_df['new_PSMId'] == 1,:]\n",
    "# compute q-values\n",
    "q_vals_SVM = calcQ(original_df_filtered_new)\n",
    "target_ID = get_target_id(q_vals_SVM)\n",
    "output_file = re.sub('.pkl', '_SVM_filtered.pkl', input_file)\n",
    "target_ID.to_pickle(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
